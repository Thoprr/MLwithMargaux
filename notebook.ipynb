{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table des Matières\n",
    "1. [Introduction et Sélection des données](#intro)\n",
    "2. [Exploration et traitement des données](#traitement)\n",
    "3. [Modélisation et évaluation](#model)\n",
    "4. [Comunication des résultats](#comm)\n",
    "5. [Retour d'expérience](#retour) \n",
    "\n",
    "  \n",
    " \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction et sélection des données <a class=\"anchor\" id=\"intro\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans le cadre de notre projet de machine Learning, nous allons traiter un sujet d'apprentissage supervisé à partir de données ouvertes. Tout au long de notre projet, nous utiliserons l'IA générative (ChatGPT) pour nous aider dans notre travail. \n",
    "\n",
    "Dans un premier temps, nous commençons par demander à ChatGPT des idées de sujets.\n",
    "\n",
    "Jeu de données ML généré par l'IA \n",
    "- DPE (Analyse énergétique, classification des logements)\n",
    "- Transports en commun (prédiction affluence, optimisation trajet)\n",
    "- Pollution (prédiction des pics de pollution, classification zones polluées)\n",
    "- Reconnaissance d'image\n",
    "- Traitement du langage naturel\n",
    "- Donnée de santé\n",
    "- Donnée financière économique (prédiction de tendance..)\n",
    "\n",
    "Analyse critique de l'IA\n",
    "L'IA propose souvent des sujets très classiques, déjà réalisé. Il propose même des projets déjà tout fait sur Kaggle. Il manque d'originalité ! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Données initiales <a class=\"anchor\" id=\"intro\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Changement de Problématique : Explication**\n",
    "\n",
    "Initialement de notre projet portait sur la prédiction des passoires thermiques à partir des données DPE : **Quels logements sont susceptibles d’être classés comme passoires thermiques (classe F ou G) ?** \n",
    "\n",
    "Cependant, après une analyse approfondie des données, nous avons décidé de changer de jeu de données et de problématique.\n",
    "\n",
    "La problématique initiale, s'est révélée trop simple pour un sujet de machine learning. Les données DPE sont directement corrélées avec les passoires thermiques, ce qui limite les défis en termes de modélisation et d'analyse.\n",
    "\n",
    "Nous avons donc opté pour une nouvelle problématique, avec un jeu de données moins binaires. \n",
    "\n",
    "\n",
    "**Problématique générée avec L'IA sur les données DPE**\n",
    "\n",
    "- Peut-on prédire la consommation énergétique d’un logement à partir de ses caractéristiques issues du DPE ?\n",
    "- Quels logements sont susceptibles d’être classés comme passoires thermiques (classe F ou G) ?\n",
    "- Peut-on prédire la classe énergétique (A à G) d’un logement à partir des caractéristiques fournies par le DPE ?\n",
    "\n",
    "**Critique de l'IA sur notre approche précedente**\n",
    "\n",
    "Votre approche est bien structurée et inclut des variables clés dans des domaines pertinents pour prédire si un logement est une passoire thermique. \n",
    "\n",
    "Points positifs :\n",
    "Les variables sélectionnées correspondent bien à des déterminants majeurs de la performance énergétique.\n",
    "Vous incluez à la fois des variables quantitatives (ex. : consommation énergétique, déperditions) et qualitatives (ex. : type d'installation de chauffage, zone climatique), ce qui permet une modélisation riche.\n",
    "\n",
    "Critiques et suggestions :\n",
    "Les bases de données DPE peuvent contenir des valeurs manquantes ou aberrantes (ex. : surfaces non renseignées, consommations incohérentes).\n",
    "Vérifiez les distributions des variables pour détecter des anomalies.\n",
    "Plusieurs variables peuvent être fortement corrélées. Une analyse des corrélations peut être utile.\n",
    "Les passoires thermiques (F et G) pourraient représenter une minorité des données. Cela peut biaiser l’entraînement du modèle.\n",
    "Les bâtiments anciens sont souvent surreprésentés parmi les passoires thermiques, ce qui peut conduire le modèle à négliger d'autres facteurs. Une analyse exploratoire approfondie est nécessaire.\n",
    "Les algorithmes robustes pour ce type de problème incluent :\n",
    " Forêts aléatoires (Random Forests): pour leur interprétabilité et leur capacité à gérer des variables mixtes.\n",
    " Gradient Boosting (XGBoost, LightGBM) : pour leur performance sur des ensembles déséquilibrés.\n",
    " Réseaux de neurones : si les données sont enrichies avec des caractéristiques complexes (géographiques, temporelles).\n",
    "\n",
    "lien données DPE : https://drive.google.com/file/d/1nUbA6m3SQ9PXpc9i9tD6yADe0fDFYKTc/view?usp=drive_link\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Données définitives <a class=\"anchor\" id=\"intro\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flight = pd.read_csv(\"data/itineraries_sample.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afin de répondre à notre problématique, nous utilisons un jeu de données issu de vols aller simple du site Expedia entre le 16 avril 2022 et le 5 octobre 2022. \n",
    "\n",
    "Voici l'intégralité des variables présentes dans notre jeu de données : \n",
    "\n",
    "- **Identifiants et Dates**  \n",
    "  - `legId` : Identifiant unique pour chaque vol.  \n",
    "  - `searchDate` : Date de la recherche effectuée sur Expedia (AAAA-MM-JJ).  \n",
    "  - `flightDate` : Date du vol (AAAA-MM-JJ).  \n",
    "\n",
    "- **Informations sur les Aéroports**  \n",
    "  - `startingAirport` : Code IATA (trois caractères) de l’aéroport de départ.  \n",
    "  - `destinationAirport` : Code IATA (trois caractères) de l’aéroport d’arrivée.  \n",
    "\n",
    "- **Tarification et Conditions**  \n",
    "  - `fareBasisCode` : Code de base tarifaire.  \n",
    "  - `baseFare` : Tarif de base du billet (en USD).  \n",
    "  - `totalFare` : Tarif total incluant taxes et frais (en USD).  \n",
    "  - `isBasicEconomy` : Indique si le billet appartient à la classe économique basique (booléen).  \n",
    "  - `isRefundable` : Indique si le billet est remboursable (booléen).  \n",
    "\n",
    "- **Caractéristiques du Vol**  \n",
    "  - `isNonStop` : Indique si le vol est direct (booléen).  \n",
    "  - `travelDuration` : Durée totale du trajet (heures et minutes).  \n",
    "  - `elapsedDays` : Nombre de jours écoulés avant le vol.  \n",
    "  - `seatsRemaining` : Nombre de sièges restants disponibles.  \n",
    "  - `totalTravelDistance` : Distance totale parcourue en miles.  \n",
    "\n",
    "- **Segments du Vol**  \n",
    "Les données contiennent également des informations détaillées sur chaque segment du trajet :  \n",
    "  - Heures de départ et d’arrivée (`segmentsDepartureTimeRaw`, `segmentsArrivalTimeRaw`).  \n",
    "  - Codes aéroportuaires des départs et arrivées (`segmentsDepartureAirportCode`, `segmentsArrivalAirportCode`).  \n",
    "  - Compagnies aériennes et avions utilisés (`segmentsAirlineName`, `segmentsEquipmentDescription`).  \n",
    "  - Durée et distance de chaque segment (`segmentsDurationInSeconds`, `segmentsDistance`).  \n",
    "  - Cabine (`segmentsCabinCode`).  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000373 entries, 0 to 1000372\n",
      "Data columns (total 27 columns):\n",
      " #   Column                             Non-Null Count    Dtype  \n",
      "---  ------                             --------------    -----  \n",
      " 0   legId                              1000373 non-null  object \n",
      " 1   searchDate                         1000373 non-null  object \n",
      " 2   flightDate                         1000373 non-null  object \n",
      " 3   startingAirport                    1000373 non-null  object \n",
      " 4   destinationAirport                 1000373 non-null  object \n",
      " 5   fareBasisCode                      1000373 non-null  object \n",
      " 6   travelDuration                     1000373 non-null  object \n",
      " 7   elapsedDays                        1000373 non-null  int64  \n",
      " 8   isBasicEconomy                     1000373 non-null  bool   \n",
      " 9   isRefundable                       1000373 non-null  bool   \n",
      " 10  isNonStop                          1000373 non-null  bool   \n",
      " 11  baseFare                           1000373 non-null  float64\n",
      " 12  totalFare                          1000373 non-null  float64\n",
      " 13  seatsRemaining                     1000373 non-null  int64  \n",
      " 14  totalTravelDistance                926181 non-null   float64\n",
      " 15  segmentsDepartureTimeEpochSeconds  1000373 non-null  object \n",
      " 16  segmentsDepartureTimeRaw           1000373 non-null  object \n",
      " 17  segmentsArrivalTimeEpochSeconds    1000373 non-null  object \n",
      " 18  segmentsArrivalTimeRaw             1000373 non-null  object \n",
      " 19  segmentsArrivalAirportCode         1000373 non-null  object \n",
      " 20  segmentsDepartureAirportCode       1000373 non-null  object \n",
      " 21  segmentsAirlineName                1000373 non-null  object \n",
      " 22  segmentsAirlineCode                1000373 non-null  object \n",
      " 23  segmentsEquipmentDescription       981430 non-null   object \n",
      " 24  segmentsDurationInSeconds          1000373 non-null  object \n",
      " 25  segmentsDistance                   990077 non-null   object \n",
      " 26  segmentsCabinCode                  1000373 non-null  object \n",
      "dtypes: bool(3), float64(3), int64(2), object(19)\n",
      "memory usage: 186.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df_flight.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration et traitement des données <a class=\"anchor\" id=\"traitement\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traitement des valeurs manquantes <a class=\"anchor\" id=\"traitement\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "legId                                0.000000\n",
       "searchDate                           0.000000\n",
       "flightDate                           0.000000\n",
       "startingAirport                      0.000000\n",
       "destinationAirport                   0.000000\n",
       "fareBasisCode                        0.000000\n",
       "travelDuration                       0.000000\n",
       "elapsedDays                          0.000000\n",
       "isBasicEconomy                       0.000000\n",
       "isRefundable                         0.000000\n",
       "isNonStop                            0.000000\n",
       "baseFare                             0.000000\n",
       "totalFare                            0.000000\n",
       "seatsRemaining                       0.000000\n",
       "totalTravelDistance                  7.416434\n",
       "segmentsDepartureTimeEpochSeconds    0.000000\n",
       "segmentsDepartureTimeRaw             0.000000\n",
       "segmentsArrivalTimeEpochSeconds      0.000000\n",
       "segmentsArrivalTimeRaw               0.000000\n",
       "segmentsArrivalAirportCode           0.000000\n",
       "segmentsDepartureAirportCode         0.000000\n",
       "segmentsAirlineName                  0.000000\n",
       "segmentsAirlineCode                  0.000000\n",
       "segmentsEquipmentDescription         1.893594\n",
       "segmentsDurationInSeconds            0.000000\n",
       "segmentsDistance                     1.029216\n",
       "segmentsCabinCode                    0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pourcentage_valeurs_manquantes = df_flight.isnull().mean() * 100\n",
    "pourcentage_valeurs_manquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "legId                                0\n",
      "searchDate                           0\n",
      "flightDate                           0\n",
      "startingAirport                      0\n",
      "destinationAirport                   0\n",
      "fareBasisCode                        0\n",
      "travelDuration                       0\n",
      "elapsedDays                          0\n",
      "isBasicEconomy                       0\n",
      "isRefundable                         0\n",
      "isNonStop                            0\n",
      "baseFare                             0\n",
      "totalFare                            0\n",
      "seatsRemaining                       0\n",
      "totalTravelDistance                  0\n",
      "segmentsDepartureTimeEpochSeconds    0\n",
      "segmentsDepartureTimeRaw             0\n",
      "segmentsArrivalTimeEpochSeconds      0\n",
      "segmentsArrivalTimeRaw               0\n",
      "segmentsArrivalAirportCode           0\n",
      "segmentsDepartureAirportCode         0\n",
      "segmentsAirlineName                  0\n",
      "segmentsAirlineCode                  0\n",
      "segmentsEquipmentDescription         0\n",
      "segmentsDurationInSeconds            0\n",
      "segmentsDistance                     0\n",
      "segmentsCabinCode                    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Retirer toutes les lignes contenant des valeurs manquantes\n",
    "df_cleaned = df_flight.dropna()\n",
    "\n",
    "# Vérifier que les valeurs manquantes ont été supprimées\n",
    "print(df_cleaned.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sélection des données** \n",
    "\n",
    "Dans un premier temps, nous sélectionnons les variables qui nous semblent pertinantes. \n",
    "\n",
    "Voici la liste des variables que nous retenons : \n",
    "- `legId`\n",
    "- `searchDate`\n",
    "- `flightDate`\n",
    "- `startingAirport`\n",
    "- `destinationAirport`\n",
    "- `fareBasisCode`\n",
    "- `travelDuration`\n",
    "- `elapsedDays`\n",
    "- `isBasicEconomy`\n",
    "- `isRefundable`\n",
    "- `isNonStop`\n",
    "- `totalFare`\n",
    "- `seatsRemaining`\n",
    "- `totalTravelDistance`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_select = [\n",
    "'legId',\n",
    "'searchDate',\n",
    "'flightDate',\n",
    "'startingAirport',\n",
    "'destinationAirport',\n",
    "'fareBasisCode',\n",
    "'travelDuration',\n",
    "'elapsedDays',\n",
    "'isBasicEconomy',\n",
    "'isRefundable',\n",
    "'isNonStop',\n",
    "'totalFare',\n",
    "'seatsRemaining',\n",
    "'totalTravelDistance'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>legId</th>\n",
       "      <th>searchDate</th>\n",
       "      <th>flightDate</th>\n",
       "      <th>startingAirport</th>\n",
       "      <th>destinationAirport</th>\n",
       "      <th>fareBasisCode</th>\n",
       "      <th>travelDuration</th>\n",
       "      <th>elapsedDays</th>\n",
       "      <th>isBasicEconomy</th>\n",
       "      <th>isRefundable</th>\n",
       "      <th>isNonStop</th>\n",
       "      <th>totalFare</th>\n",
       "      <th>seatsRemaining</th>\n",
       "      <th>totalTravelDistance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6203bbd77fbd8e40021ee3e88ffa9edc</td>\n",
       "      <td>2022-04-16</td>\n",
       "      <td>2022-04-17</td>\n",
       "      <td>ATL</td>\n",
       "      <td>IAD</td>\n",
       "      <td>KA0NA0MC</td>\n",
       "      <td>PT12H22M</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>746.14</td>\n",
       "      <td>2</td>\n",
       "      <td>1224.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34bb71c85bd77485193f5d83c553d783</td>\n",
       "      <td>2022-04-16</td>\n",
       "      <td>2022-04-17</td>\n",
       "      <td>ATL</td>\n",
       "      <td>JFK</td>\n",
       "      <td>EAA0OKEN</td>\n",
       "      <td>PT9H15M</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>672.19</td>\n",
       "      <td>1</td>\n",
       "      <td>762.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>691ae27539fcaab7ea209c67d36a6bdb</td>\n",
       "      <td>2022-04-16</td>\n",
       "      <td>2022-04-17</td>\n",
       "      <td>ATL</td>\n",
       "      <td>LAX</td>\n",
       "      <td>V0AGZNN1</td>\n",
       "      <td>PT7H47M</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>370.60</td>\n",
       "      <td>4</td>\n",
       "      <td>1954.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5acd2ad9bbc5dfcdbfb2d70920c45a55</td>\n",
       "      <td>2022-04-16</td>\n",
       "      <td>2022-04-17</td>\n",
       "      <td>ATL</td>\n",
       "      <td>LAX</td>\n",
       "      <td>MA0QA0MQ</td>\n",
       "      <td>PT4H57M</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>598.61</td>\n",
       "      <td>7</td>\n",
       "      <td>1943.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>48250c83294e10c36c992ec208fc62f7</td>\n",
       "      <td>2022-04-16</td>\n",
       "      <td>2022-04-17</td>\n",
       "      <td>ATL</td>\n",
       "      <td>LGA</td>\n",
       "      <td>KA0NX0MQ</td>\n",
       "      <td>PT2H12M</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>244.60</td>\n",
       "      <td>1</td>\n",
       "      <td>762.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000368</th>\n",
       "      <td>9877500f9069b28d3bbde94206bb48c0</td>\n",
       "      <td>2022-10-05</td>\n",
       "      <td>2022-11-12</td>\n",
       "      <td>DFW</td>\n",
       "      <td>MIA</td>\n",
       "      <td>VUAWZNN1</td>\n",
       "      <td>PT6H55M</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>244.60</td>\n",
       "      <td>7</td>\n",
       "      <td>2100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000369</th>\n",
       "      <td>75f5c5422edf8d0074b624106170fc2f</td>\n",
       "      <td>2022-10-05</td>\n",
       "      <td>2022-11-12</td>\n",
       "      <td>DFW</td>\n",
       "      <td>OAK</td>\n",
       "      <td>GH4OAJBN</td>\n",
       "      <td>PT7H42M</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>152.60</td>\n",
       "      <td>7</td>\n",
       "      <td>2335.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000370</th>\n",
       "      <td>b48181202b764fa7fddbf23823fa2903</td>\n",
       "      <td>2022-10-05</td>\n",
       "      <td>2022-11-12</td>\n",
       "      <td>DFW</td>\n",
       "      <td>PHL</td>\n",
       "      <td>TAVOA0BG</td>\n",
       "      <td>PT6H29M</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>158.60</td>\n",
       "      <td>9</td>\n",
       "      <td>1392.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000371</th>\n",
       "      <td>5ed2af184418e2a2f67d2839a593c1e9</td>\n",
       "      <td>2022-10-05</td>\n",
       "      <td>2022-11-12</td>\n",
       "      <td>DFW</td>\n",
       "      <td>PHL</td>\n",
       "      <td>QUAIXSM3</td>\n",
       "      <td>PT9H49M</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>463.20</td>\n",
       "      <td>7</td>\n",
       "      <td>1304.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000372</th>\n",
       "      <td>2d35bda23efba477bf783376a97a25cc</td>\n",
       "      <td>2022-10-05</td>\n",
       "      <td>2022-11-12</td>\n",
       "      <td>ORD</td>\n",
       "      <td>ATL</td>\n",
       "      <td>NUAIXSB3</td>\n",
       "      <td>PT7H19M</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>137.60</td>\n",
       "      <td>7</td>\n",
       "      <td>1492.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>910463 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    legId  searchDate  flightDate  \\\n",
       "1        6203bbd77fbd8e40021ee3e88ffa9edc  2022-04-16  2022-04-17   \n",
       "2        34bb71c85bd77485193f5d83c553d783  2022-04-16  2022-04-17   \n",
       "3        691ae27539fcaab7ea209c67d36a6bdb  2022-04-16  2022-04-17   \n",
       "4        5acd2ad9bbc5dfcdbfb2d70920c45a55  2022-04-16  2022-04-17   \n",
       "5        48250c83294e10c36c992ec208fc62f7  2022-04-16  2022-04-17   \n",
       "...                                   ...         ...         ...   \n",
       "1000368  9877500f9069b28d3bbde94206bb48c0  2022-10-05  2022-11-12   \n",
       "1000369  75f5c5422edf8d0074b624106170fc2f  2022-10-05  2022-11-12   \n",
       "1000370  b48181202b764fa7fddbf23823fa2903  2022-10-05  2022-11-12   \n",
       "1000371  5ed2af184418e2a2f67d2839a593c1e9  2022-10-05  2022-11-12   \n",
       "1000372  2d35bda23efba477bf783376a97a25cc  2022-10-05  2022-11-12   \n",
       "\n",
       "        startingAirport destinationAirport fareBasisCode travelDuration  \\\n",
       "1                   ATL                IAD      KA0NA0MC       PT12H22M   \n",
       "2                   ATL                JFK      EAA0OKEN        PT9H15M   \n",
       "3                   ATL                LAX      V0AGZNN1        PT7H47M   \n",
       "4                   ATL                LAX      MA0QA0MQ        PT4H57M   \n",
       "5                   ATL                LGA      KA0NX0MQ        PT2H12M   \n",
       "...                 ...                ...           ...            ...   \n",
       "1000368             DFW                MIA      VUAWZNN1        PT6H55M   \n",
       "1000369             DFW                OAK      GH4OAJBN        PT7H42M   \n",
       "1000370             DFW                PHL      TAVOA0BG        PT6H29M   \n",
       "1000371             DFW                PHL      QUAIXSM3        PT9H49M   \n",
       "1000372             ORD                ATL      NUAIXSB3        PT7H19M   \n",
       "\n",
       "         elapsedDays  isBasicEconomy  isRefundable  isNonStop  totalFare  \\\n",
       "1                  0           False         False      False     746.14   \n",
       "2                  0           False         False      False     672.19   \n",
       "3                  0           False         False      False     370.60   \n",
       "4                  0           False         False       True     598.61   \n",
       "5                  0           False         False       True     244.60   \n",
       "...              ...             ...           ...        ...        ...   \n",
       "1000368            0           False         False      False     244.60   \n",
       "1000369            0            True         False      False     152.60   \n",
       "1000370            0            True         False      False     158.60   \n",
       "1000371            1           False         False      False     463.20   \n",
       "1000372            0            True         False      False     137.60   \n",
       "\n",
       "         seatsRemaining  totalTravelDistance  \n",
       "1                     2               1224.0  \n",
       "2                     1                762.0  \n",
       "3                     4               1954.0  \n",
       "4                     7               1943.0  \n",
       "5                     1                762.0  \n",
       "...                 ...                  ...  \n",
       "1000368               7               2100.0  \n",
       "1000369               7               2335.0  \n",
       "1000370               9               1392.0  \n",
       "1000371               7               1304.0  \n",
       "1000372               7               1492.0  \n",
       "\n",
       "[910463 rows x 14 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned = df_cleaned[var_select]\n",
    "df_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corrélation entre les variables <a class=\"anchor\" id=\"traitement\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Répartion des variables <a class=\"anchor\" id=\"traitement\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>daysBetweenSearchAndFlight</th>\n",
       "      <th>startingAirport</th>\n",
       "      <th>destinationAirport</th>\n",
       "      <th>searchMonth</th>\n",
       "      <th>searchDayOfWeek</th>\n",
       "      <th>flightYear</th>\n",
       "      <th>flightMonth</th>\n",
       "      <th>flightDayOfWeek</th>\n",
       "      <th>flightWeekend</th>\n",
       "      <th>fareType</th>\n",
       "      <th>elapsedDays</th>\n",
       "      <th>isOvernightFlight</th>\n",
       "      <th>totalTravelDistance</th>\n",
       "      <th>distanceBands</th>\n",
       "      <th>travelDurationMinutes</th>\n",
       "      <th>totalFare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ATL</td>\n",
       "      <td>IAD</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>Economy</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1224.0</td>\n",
       "      <td>medium-haul</td>\n",
       "      <td>742.0</td>\n",
       "      <td>746.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>ATL</td>\n",
       "      <td>JFK</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>Economy</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>762.0</td>\n",
       "      <td>medium-haul</td>\n",
       "      <td>555.0</td>\n",
       "      <td>672.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>ATL</td>\n",
       "      <td>LAX</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>Economy</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1954.0</td>\n",
       "      <td>long-haul</td>\n",
       "      <td>467.0</td>\n",
       "      <td>370.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>ATL</td>\n",
       "      <td>LAX</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>Economy</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1943.0</td>\n",
       "      <td>long-haul</td>\n",
       "      <td>297.0</td>\n",
       "      <td>598.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>ATL</td>\n",
       "      <td>LGA</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>Economy</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>762.0</td>\n",
       "      <td>medium-haul</td>\n",
       "      <td>132.0</td>\n",
       "      <td>244.60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   daysBetweenSearchAndFlight startingAirport destinationAirport  searchMonth  \\\n",
       "1                           1             ATL                IAD            4   \n",
       "2                           1             ATL                JFK            4   \n",
       "3                           1             ATL                LAX            4   \n",
       "4                           1             ATL                LAX            4   \n",
       "5                           1             ATL                LGA            4   \n",
       "\n",
       "   searchDayOfWeek  flightYear  flightMonth  flightDayOfWeek  flightWeekend  \\\n",
       "1                5        2022            4                6           True   \n",
       "2                5        2022            4                6           True   \n",
       "3                5        2022            4                6           True   \n",
       "4                5        2022            4                6           True   \n",
       "5                5        2022            4                6           True   \n",
       "\n",
       "  fareType  elapsedDays  isOvernightFlight  totalTravelDistance distanceBands  \\\n",
       "1  Economy            0              False               1224.0   medium-haul   \n",
       "2  Economy            0              False                762.0   medium-haul   \n",
       "3  Economy            0              False               1954.0     long-haul   \n",
       "4  Economy            0              False               1943.0     long-haul   \n",
       "5  Economy            0              False                762.0   medium-haul   \n",
       "\n",
       "   travelDurationMinutes  totalFare  \n",
       "1                  742.0     746.14  \n",
       "2                  555.0     672.19  \n",
       "3                  467.0     370.60  \n",
       "4                  297.0     598.61  \n",
       "5                  132.0     244.60  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# ===============================\n",
    "# 0) Définition d'une fonction\n",
    "#    pour parser la durée ISO 8601\n",
    "# ===============================\n",
    "def parse_iso8601_duration(duration_str):\n",
    "    \"\"\"\n",
    "    Convertit une durée au format ISO 8601 (ex: 'PT4H57M') \n",
    "    en un nombre entier de minutes.\n",
    "    Si la chaîne est invalide ou NaN, renvoie np.nan.\n",
    "    \"\"\"\n",
    "    if pd.isnull(duration_str):\n",
    "        return np.nan\n",
    "    \n",
    "    # Pattern simplifié pour extraire heures (H) et minutes (M), ex: PT4H57M\n",
    "    pattern = r'^PT(?:(\\d+)H)?(?:(\\d+)M)?$'\n",
    "    match = re.match(pattern, duration_str.strip())\n",
    "    if not match:\n",
    "        return np.nan  # Format non conforme ou autre\n",
    "    \n",
    "    hours_str, minutes_str = match.groups()\n",
    "    hours = int(hours_str) if hours_str else 0\n",
    "    minutes = int(minutes_str) if minutes_str else 0\n",
    "    \n",
    "    total_minutes = hours * 60 + minutes\n",
    "    return total_minutes\n",
    "\n",
    "# ===============================\n",
    "# 1) Conversion des dates\n",
    "# ===============================\n",
    "df_cleaned['searchDate'] = pd.to_datetime(df_cleaned['searchDate'], errors='coerce')\n",
    "df_cleaned['flightDate'] = pd.to_datetime(df_cleaned['flightDate'], errors='coerce')\n",
    "\n",
    "# ===============================\n",
    "# 2) daysBetweenSearchAndFlight\n",
    "#    (flightDate - searchDate) en jours\n",
    "# ===============================\n",
    "df_cleaned['daysBetweenSearchAndFlight'] = (df_cleaned['flightDate'] - df_cleaned['searchDate']).dt.days\n",
    "\n",
    "# ===============================\n",
    "# 3) searchDayOfWeek et flightDayOfWeek\n",
    "#    (0 = Lundi, ..., 6 = Dimanche)\n",
    "# ===============================\n",
    "df_cleaned['searchDayOfWeek'] = df_cleaned['searchDate'].dt.dayofweek\n",
    "df_cleaned['flightDayOfWeek'] = df_cleaned['flightDate'].dt.dayofweek\n",
    "\n",
    "# ===============================\n",
    "# 4) searchMonth, flightMonth, flightYear\n",
    "# ===============================\n",
    "df_cleaned['searchMonth'] = df_cleaned['searchDate'].dt.month\n",
    "df_cleaned['flightMonth'] = df_cleaned['flightDate'].dt.month\n",
    "df_cleaned['flightYear'] = df_cleaned['flightDate'].dt.year\n",
    "\n",
    "# ===============================\n",
    "# 5) flightWeekend (booléen)\n",
    "#    True si Samedi ou Dimanche\n",
    "# ===============================\n",
    "df_cleaned['flightWeekend'] = df_cleaned['flightDayOfWeek'].isin([5, 6])\n",
    "\n",
    "# ===============================\n",
    "# 6) Conversion de travelDuration\n",
    "#    (ex: 'PT4H57M' -> minutes int)\n",
    "# ===============================\n",
    "df_cleaned['travelDurationMinutes'] = df_cleaned['travelDuration'].apply(parse_iso8601_duration)\n",
    "\n",
    "# ===============================\n",
    "# 7) fareType\n",
    "#    Basé sur la 1ère lettre de fareBasisCode\n",
    "# ===============================\n",
    "FIRST = {'F', 'A', 'P'}\n",
    "BUSINESS = {'C', 'J', 'D', 'I', 'Z'}\n",
    "PREMIUM_ECONOMY = {'W', 'S', 'R'}\n",
    "ECONOMY = {'Y', 'B', 'M', 'U', 'H', 'Q', 'K', 'L', 'G', 'V', 'T', 'N', 'X', 'O', 'E'}\n",
    "\n",
    "def map_fare_type(code):\n",
    "    \"\"\"\n",
    "    Retourne la cabine probable (First, Business, Premium Economy, Economy, Unknown)\n",
    "    en se basant sur la première lettre du fareBasisCode.\n",
    "    \"\"\"\n",
    "    if pd.isnull(code) or not code:\n",
    "        return 'Unknown'\n",
    "    \n",
    "    first_char = str(code).strip().upper()[0]\n",
    "    \n",
    "    if first_char in FIRST:\n",
    "        return 'First'\n",
    "    elif first_char in BUSINESS:\n",
    "        return 'Business'\n",
    "    elif first_char in PREMIUM_ECONOMY:\n",
    "        return 'Premium Economy'\n",
    "    elif first_char in ECONOMY:\n",
    "        return 'Economy'\n",
    "    else:\n",
    "        return 'Unknown'\n",
    "\n",
    "df_cleaned['fareType'] = df_cleaned['fareBasisCode'].apply(map_fare_type)\n",
    "\n",
    "# ===============================\n",
    "# 8) isOvernightFlight\n",
    "#    Si elapsedDays > 0\n",
    "# ===============================\n",
    "df_cleaned['isOvernightFlight'] = df_cleaned['elapsedDays'] > 0\n",
    "\n",
    "# ===============================\n",
    "# 9) distanceBands\n",
    "#    short-haul (<500), medium-haul (<=1500), long-haul (>1500)\n",
    "# ===============================\n",
    "def define_distance_band(x):\n",
    "    if pd.isnull(x):\n",
    "        return 'unknown'\n",
    "    elif x < 500:\n",
    "        return 'short-haul'\n",
    "    elif x <= 1500:\n",
    "        return 'medium-haul'\n",
    "    else:\n",
    "        return 'long-haul'\n",
    "\n",
    "df_cleaned['distanceBands'] = df_cleaned['totalTravelDistance'].apply(define_distance_band)\n",
    "\n",
    "# ===============================\n",
    "# 10) Constitution de df_final\n",
    "#     Avec les features finales + la cible\n",
    "# ===============================\n",
    "df_final = df_cleaned[[\n",
    "    'daysBetweenSearchAndFlight', \n",
    "    'startingAirport',\n",
    "    'destinationAirport',\n",
    "    'searchMonth', \n",
    "    'searchDayOfWeek',\n",
    "    'flightYear', \n",
    "    'flightMonth', \n",
    "    'flightDayOfWeek', \n",
    "    'flightWeekend', \n",
    "    'fareType',\n",
    "    'elapsedDays', \n",
    "    'isOvernightFlight',\n",
    "    'totalTravelDistance', \n",
    "    'distanceBands',\n",
    "    'travelDurationMinutes',      # La nouvelle colonne\n",
    "    'totalFare'\n",
    "]]\n",
    "\n",
    "# Vérification\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              model        rmse        r2\n",
      "0      DecisionTree  150.239420  0.417621\n",
      "1      RandomForest  106.998941  0.704609\n",
      "2  LinearRegression  151.092062  0.410991\n",
      "3           XGBoost  117.837593  0.641734\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Modèles\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Métriques\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# =====================\n",
    "# 1) Définition de la cible (y) et des features (X)\n",
    "target = 'totalFare'\n",
    "\n",
    "features = [\n",
    "    'daysBetweenSearchAndFlight',\n",
    "    'startingAirport',\n",
    "    'destinationAirport',\n",
    "    'searchMonth',\n",
    "    'searchDayOfWeek',\n",
    "    'flightYear',\n",
    "    'flightMonth',\n",
    "    'flightDayOfWeek',\n",
    "    'flightWeekend',\n",
    "    'fareType',\n",
    "    'elapsedDays',\n",
    "    'isOvernightFlight',\n",
    "    'totalTravelDistance',\n",
    "    'distanceBands',\n",
    "    'travelDurationMinutes'\n",
    "]\n",
    "\n",
    "# On suppose que df_final contient déjà ces colonnes\n",
    "X = df_final[features].copy()\n",
    "y = df_final[target].copy()\n",
    "\n",
    "# =====================\n",
    "# 2) Séparation en train et test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# =====================\n",
    "# 3) Gestion des booléens (optionnel)\n",
    "#    Si tu préfères traiter flightWeekend, isOvernightFlight en 0/1 (numérique):\n",
    "bool_cols = ['flightWeekend', 'isOvernightFlight']\n",
    "for col in bool_cols:\n",
    "    X_train[col] = X_train[col].astype(int, errors=\"ignore\")\n",
    "    X_test[col] = X_test[col].astype(int, errors=\"ignore\")\n",
    "\n",
    "# =====================\n",
    "# 4) Identification des colonnes numériques et catégorielles\n",
    "#    Selon ton choix, on traite flightWeekend, isOvernightFlight comme numériques.\n",
    "numeric_features = [\n",
    "    'daysBetweenSearchAndFlight',\n",
    "    'searchMonth',\n",
    "    'searchDayOfWeek',\n",
    "    'flightYear',\n",
    "    'flightMonth',\n",
    "    'flightDayOfWeek',\n",
    "    'elapsedDays',\n",
    "    'flightWeekend',\n",
    "    'isOvernightFlight',\n",
    "    'totalTravelDistance',\n",
    "    'travelDurationMinutes'\n",
    "]\n",
    "\n",
    "# Pour les colonnes purement catégorielles\n",
    "categorical_features = [\n",
    "    'fareType',\n",
    "    'distanceBands',\n",
    "    'startingAirport',\n",
    "    'destinationAirport'\n",
    "]\n",
    "\n",
    "# =====================\n",
    "# 5) Construction du préprocesseur avec ColumnTransformer\n",
    "from sklearn.compose import make_column_selector\n",
    "\n",
    "numeric_transformer = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")),   # Remplacement des NaN\n",
    "    (\"scaler\", StandardScaler())                   # Mise à l'échelle standard\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"missing\")),  \n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))                     \n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", numeric_transformer, numeric_features),\n",
    "    (\"cat\", categorical_transformer, categorical_features)\n",
    "])\n",
    "\n",
    "# =====================\n",
    "# 6) Définition des modèles à tester\n",
    "models = {\n",
    "    \"DecisionTree\": DecisionTreeRegressor(random_state=42),\n",
    "    \"RandomForest\": RandomForestRegressor(random_state=42),\n",
    "    \"LinearRegression\": LinearRegression(),\n",
    "    \"XGBoost\": XGBRegressor(random_state=42, verbosity=0)\n",
    "}\n",
    "\n",
    "# =====================\n",
    "# 7) Entraînement et évaluation de chaque modèle\n",
    "results = []\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    # Pipeline = Preprocessing + Modèle\n",
    "    pipe = Pipeline([\n",
    "        (\"preprocessing\", preprocessor),\n",
    "        (\"regressor\", model)\n",
    "    ])\n",
    "    \n",
    "    # Entraînement\n",
    "    pipe.fit(X_train, y_train)\n",
    "    \n",
    "    # Prédiction sur le test set\n",
    "    y_pred = pipe.predict(X_test)\n",
    "    \n",
    "    # Évaluation\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    results.append({\n",
    "        \"model\": model_name,\n",
    "        \"rmse\": rmse,\n",
    "        \"r2\": r2\n",
    "    })\n",
    "\n",
    "# =====================\n",
    "# 8) Affichage des résultats\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== RandomForest GridSearch ==========\n",
      "Best params (RF): {'regressor__max_depth': None, 'regressor__min_samples_leaf': 1, 'regressor__n_estimators': 100}\n",
      "Best CV score (RF - RMSE): 112.66567744123013\n",
      "[RF] Test set RMSE: 107.00, R²: 0.705\n",
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
      "\n",
      "========== XGBoost GridSearch ==========\n",
      "Best params (XGB): {'regressor__learning_rate': 0.1, 'regressor__max_depth': 10, 'regressor__n_estimators': 200, 'regressor__subsample': 0.8}\n",
      "Best CV score (XGB - RMSE): 110.94292108539868\n",
      "[XGB] Test set RMSE: 106.84, R²: 0.705\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Modèles\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Métriques\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "###############################################################################\n",
    "# 1) Définition de la cible et des features\n",
    "###############################################################################\n",
    "target = 'totalFare'\n",
    "\n",
    "# Ton jeu de features, y compris les aéroports et la duration en minutes\n",
    "features = [\n",
    "    'daysBetweenSearchAndFlight',\n",
    "    'startingAirport',\n",
    "    'destinationAirport',\n",
    "    'searchMonth',\n",
    "    'searchDayOfWeek',\n",
    "    'flightYear',\n",
    "    'flightMonth',\n",
    "    'flightDayOfWeek',\n",
    "    'flightWeekend',\n",
    "    'fareType',\n",
    "    'elapsedDays',\n",
    "    'isOvernightFlight',\n",
    "    'totalTravelDistance',\n",
    "    'distanceBands',\n",
    "    'travelDurationMinutes'\n",
    "]\n",
    "\n",
    "# On suppose que df_final est déjà disponible et contient ces colonnes\n",
    "X = df_final[features].copy()\n",
    "y = df_final[target].copy()\n",
    "\n",
    "# Séparation train / test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "###############################################################################\n",
    "# 2) Conversion des booléens (flightWeekend, isOvernightFlight) en int (0/1)\n",
    "###############################################################################\n",
    "bool_cols = ['flightWeekend', 'isOvernightFlight']\n",
    "for col in bool_cols:\n",
    "    X_train[col] = X_train[col].astype(int, errors=\"ignore\")\n",
    "    X_test[col] = X_test[col].astype(int, errors=\"ignore\")\n",
    "\n",
    "###############################################################################\n",
    "# 3) Distinction colonnes numériques vs. colonnes catégorielles\n",
    "###############################################################################\n",
    "numeric_features = [\n",
    "    'daysBetweenSearchAndFlight',\n",
    "    'searchMonth',\n",
    "    'searchDayOfWeek',\n",
    "    'flightYear',\n",
    "    'flightMonth',\n",
    "    'flightDayOfWeek',\n",
    "    'elapsedDays',\n",
    "    'flightWeekend',\n",
    "    'isOvernightFlight',\n",
    "    'totalTravelDistance',\n",
    "    'travelDurationMinutes'\n",
    "]\n",
    "\n",
    "categorical_features = [\n",
    "    'fareType',\n",
    "    'distanceBands',\n",
    "    'startingAirport',\n",
    "    'destinationAirport'\n",
    "]\n",
    "\n",
    "# Prétraitement : imputation + standardisation pour numeric, imputation + OneHot pour categorical\n",
    "numeric_transformer = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"missing\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", numeric_transformer, numeric_features),\n",
    "    (\"cat\", categorical_transformer, categorical_features)\n",
    "])\n",
    "\n",
    "###############################################################################\n",
    "# 4) GridSearchCV pour RandomForest\n",
    "###############################################################################\n",
    "pipe_rf = Pipeline([\n",
    "    (\"preprocessing\", preprocessor),\n",
    "    (\"regressor\", RandomForestRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "# Exemple d'hyperparamètres (à ajuster selon tes besoins)\n",
    "param_grid_rf = {\n",
    "    \"regressor__n_estimators\": [50, 100],\n",
    "    \"regressor__max_depth\": [None, 10, 20],\n",
    "    \"regressor__min_samples_leaf\": [1, 5]\n",
    "}\n",
    "\n",
    "grid_search_rf = GridSearchCV(\n",
    "    estimator=pipe_rf,\n",
    "    param_grid=param_grid_rf,\n",
    "    cv=3,  # 3-fold cross validation\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Entraînement\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "print(\"========== RandomForest GridSearch ==========\")\n",
    "print(\"Best params (RF):\", grid_search_rf.best_params_)\n",
    "print(\"Best CV score (RF - RMSE):\", -grid_search_rf.best_score_)\n",
    "\n",
    "# Évaluation sur le test set\n",
    "best_rf_model = grid_search_rf.best_estimator_\n",
    "y_pred_rf = best_rf_model.predict(X_test)\n",
    "rmse_rf = np.sqrt(mean_squared_error(y_test, y_pred_rf))\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "print(f\"[RF] Test set RMSE: {rmse_rf:.2f}, R²: {r2_rf:.3f}\")\n",
    "\n",
    "###############################################################################\n",
    "# 5) GridSearchCV pour XGBoost (optionnel)\n",
    "###############################################################################\n",
    "pipe_xgb = Pipeline([\n",
    "    (\"preprocessing\", preprocessor),\n",
    "    (\"regressor\", XGBRegressor(random_state=42, verbosity=0))\n",
    "])\n",
    "\n",
    "param_grid_xgb = {\n",
    "    \"regressor__n_estimators\": [100, 200],\n",
    "    \"regressor__max_depth\": [3, 6, 10],\n",
    "    \"regressor__learning_rate\": [0.01, 0.1],\n",
    "    \"regressor__subsample\": [0.8, 1.0]\n",
    "}\n",
    "\n",
    "grid_search_xgb = GridSearchCV(\n",
    "    estimator=pipe_xgb,\n",
    "    param_grid=param_grid_xgb,\n",
    "    cv=3,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search_xgb.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\n========== XGBoost GridSearch ==========\")\n",
    "print(\"Best params (XGB):\", grid_search_xgb.best_params_)\n",
    "print(\"Best CV score (XGB - RMSE):\", -grid_search_xgb.best_score_)\n",
    "\n",
    "best_xgb_model = grid_search_xgb.best_estimator_\n",
    "y_pred_xgb = best_xgb_model.predict(X_test)\n",
    "rmse_xgb = np.sqrt(mean_squared_error(y_test, y_pred_xgb))\n",
    "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
    "print(f\"[XGB] Test set RMSE: {rmse_xgb:.2f}, R²: {r2_xgb:.3f}\")\n",
    "\n",
    "###############################################################################\n",
    "# 6) Conclusion\n",
    "###############################################################################\n",
    "# Tu obtiens:\n",
    "# - Meilleurs hyperparamètres pour RandomForest & XGBoost\n",
    "# - Leurs performances RMSE / R² sur le set de test\n",
    "###############################################################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
