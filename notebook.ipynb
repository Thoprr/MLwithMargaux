{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table des Matières\n",
    "1. [Introduction et Sélection des données](#intro)\n",
    "2. [Exploration et traitement des données](#traitement)\n",
    "3. [Modélisation et évaluation](#model)\n",
    "4. [Comunication des résultats](#comm)\n",
    "5. [Retour d'expérience](#retour) \n",
    "\n",
    "  \n",
    " \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction et sélection des données <a class=\"anchor\" id=\"intro\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans le cadre de notre projet de machine Learning, nous allons traiter un sujet d'apprentissage supervisé à partir de données ouvertes. Tout au long de notre projet, nous utiliserons l'IA générative (ChatGPT) pour nous aider dans notre travail. \n",
    "\n",
    "Dans un premier temps, nous commençons par demander à ChatGPT des idées de sujets.\n",
    "\n",
    "Jeu de données ML généré par l'IA \n",
    "- DPE (Analyse énergétique, classification des logements)\n",
    "- Transports en commun (prédiction affluence, optimisation trajet)\n",
    "- Pollution (prédiction des pics de pollution, classification zones polluées)\n",
    "- Reconnaissance d'image\n",
    "- Traitement du langage naturel\n",
    "- Donnée de santé\n",
    "- Donnée financière économique (prédiction de tendance..)\n",
    "\n",
    "Analyse critique de l'IA\n",
    "L'IA propose souvent des sujets très classiques, déjà réalisé. Il propose même des projets déjà tout fait sur Kaggle. Il manque d'originalité ! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Données initiales <a class=\"anchor\" id=\"intro\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Changement de Problématique : Explication**\n",
    "\n",
    "Initialement de notre projet portait sur la prédiction des passoires thermiques à partir des données DPE : **Quels logements sont susceptibles d’être classés comme passoires thermiques (classe F ou G) ?** \n",
    "\n",
    "Cependant, après une analyse approfondie des données, nous avons décidé de changer de jeu de données et de problématique.\n",
    "\n",
    "La problématique initiale, s'est révélée trop simple pour un sujet de machine learning. Les données DPE sont directement corrélées avec les passoires thermiques, ce qui limite les défis en termes de modélisation et d'analyse.\n",
    "\n",
    "Nous avons donc opté pour une nouvelle problématique, avec un jeu de données moins binaires. \n",
    "\n",
    "\n",
    "**Problématique générée avec L'IA sur les données DPE**\n",
    "\n",
    "- Peut-on prédire la consommation énergétique d’un logement à partir de ses caractéristiques issues du DPE ?\n",
    "- Quels logements sont susceptibles d’être classés comme passoires thermiques (classe F ou G) ?\n",
    "- Peut-on prédire la classe énergétique (A à G) d’un logement à partir des caractéristiques fournies par le DPE ?\n",
    "\n",
    "**Critique de l'IA sur notre approche précedente**\n",
    "\n",
    "Votre approche est bien structurée et inclut des variables clés dans des domaines pertinents pour prédire si un logement est une passoire thermique. \n",
    "\n",
    "Points positifs :\n",
    "Les variables sélectionnées correspondent bien à des déterminants majeurs de la performance énergétique.\n",
    "Vous incluez à la fois des variables quantitatives (ex. : consommation énergétique, déperditions) et qualitatives (ex. : type d'installation de chauffage, zone climatique), ce qui permet une modélisation riche.\n",
    "\n",
    "Critiques et suggestions :\n",
    "Les bases de données DPE peuvent contenir des valeurs manquantes ou aberrantes (ex. : surfaces non renseignées, consommations incohérentes).\n",
    "Vérifiez les distributions des variables pour détecter des anomalies.\n",
    "Plusieurs variables peuvent être fortement corrélées. Une analyse des corrélations peut être utile.\n",
    "Les passoires thermiques (F et G) pourraient représenter une minorité des données. Cela peut biaiser l’entraînement du modèle.\n",
    "Les bâtiments anciens sont souvent surreprésentés parmi les passoires thermiques, ce qui peut conduire le modèle à négliger d'autres facteurs. Une analyse exploratoire approfondie est nécessaire.\n",
    "Les algorithmes robustes pour ce type de problème incluent :\n",
    " Forêts aléatoires (Random Forests): pour leur interprétabilité et leur capacité à gérer des variables mixtes.\n",
    " Gradient Boosting (XGBoost, LightGBM) : pour leur performance sur des ensembles déséquilibrés.\n",
    " Réseaux de neurones : si les données sont enrichies avec des caractéristiques complexes (géographiques, temporelles).\n",
    "\n",
    "lien données DPE : https://drive.google.com/file/d/1nUbA6m3SQ9PXpc9i9tD6yADe0fDFYKTc/view?usp=drive_link\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Données définitives <a class=\"anchor\" id=\"intro\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flight = pd.read_csv(\"data/itineraries_sample.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afin de répondre à notre problématique, nous utilisons un jeu de données issu de vols aller simple du site Expedia entre le 16 avril 2022 et le 5 octobre 2022. \n",
    "\n",
    "Voici l'intégralité des variables présentes dans notre jeu de données : \n",
    "\n",
    "- **Identifiants et Dates**  \n",
    "  - `legId` : Identifiant unique pour chaque vol.  \n",
    "  - `searchDate` : Date de la recherche effectuée sur Expedia (AAAA-MM-JJ).  \n",
    "  - `flightDate` : Date du vol (AAAA-MM-JJ).  \n",
    "\n",
    "- **Informations sur les Aéroports**  \n",
    "  - `startingAirport` : Code IATA (trois caractères) de l’aéroport de départ.  \n",
    "  - `destinationAirport` : Code IATA (trois caractères) de l’aéroport d’arrivée.  \n",
    "\n",
    "- **Tarification et Conditions**  \n",
    "  - `fareBasisCode` : Code de base tarifaire.  \n",
    "  - `baseFare` : Tarif de base du billet (en USD).  \n",
    "  - `totalFare` : Tarif total incluant taxes et frais (en USD).  \n",
    "  - `isBasicEconomy` : Indique si le billet appartient à la classe économique basique (booléen).  \n",
    "  - `isRefundable` : Indique si le billet est remboursable (booléen).  \n",
    "\n",
    "- **Caractéristiques du Vol**  \n",
    "  - `isNonStop` : Indique si le vol est direct (booléen).  \n",
    "  - `travelDuration` : Durée totale du trajet (heures et minutes).  \n",
    "  - `elapsedDays` : Nombre de jours écoulés avant le vol.  \n",
    "  - `seatsRemaining` : Nombre de sièges restants disponibles.  \n",
    "  - `totalTravelDistance` : Distance totale parcourue en miles.  \n",
    "\n",
    "- **Segments du Vol**  \n",
    "Les données contiennent également des informations détaillées sur chaque segment du trajet :  \n",
    "  - Heures de départ et d’arrivée (`segmentsDepartureTimeRaw`, `segmentsArrivalTimeRaw`).  \n",
    "  - Codes aéroportuaires des départs et arrivées (`segmentsDepartureAirportCode`, `segmentsArrivalAirportCode`).  \n",
    "  - Compagnies aériennes et avions utilisés (`segmentsAirlineName`, `segmentsEquipmentDescription`).  \n",
    "  - Durée et distance de chaque segment (`segmentsDurationInSeconds`, `segmentsDistance`).  \n",
    "  - Cabine (`segmentsCabinCode`).  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flight.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sélection des données** \n",
    "\n",
    "Dans un premier temps, nous sélectionnons les variables qui nous semblent pertinantes. \n",
    "\n",
    "Voici la liste des variables que nous retenons : \n",
    "- `legId`\n",
    "- `searchDate`\n",
    "- `flightDate`\n",
    "- `startingAirport`\n",
    "- `destinationAirport`\n",
    "- `fareBasisCode`\n",
    "- `travelDuration`\n",
    "- `elapsedDays`\n",
    "- `isBasicEconomy`\n",
    "- `isRefundable`\n",
    "- `isNonStop`\n",
    "- `totalFare`\n",
    "- `seatsRemaining`\n",
    "- `totalTravelDistance`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_select = [\n",
    "'legId',\n",
    "'searchDate',\n",
    "'flightDate',\n",
    "'startingAirport',\n",
    "'destinationAirport',\n",
    "'fareBasisCode',\n",
    "'travelDuration',\n",
    "'elapsedDays',\n",
    "'isBasicEconomy',\n",
    "'isRefundable',\n",
    "'isNonStop',\n",
    "'totalFare',\n",
    "'seatsRemaining',\n",
    "'totalTravelDistance'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration et traitement des données <a class=\"anchor\" id=\"traitement\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traitement des valeurs manquantes <a class=\"anchor\" id=\"traitement\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pourcentage_valeurs_manquantes = df_flight.isnull().mean() * 100\n",
    "pourcentage_valeurs_manquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retirer toutes les lignes contenant des valeurs manquantes\n",
    "df_cleaned = df_flight.dropna()\n",
    "\n",
    "# Vérifier que les valeurs manquantes ont été supprimées\n",
    "print(df_cleaned.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df_cleaned[var_select]\n",
    "df_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corrélation entre les variables <a class=\"anchor\" id=\"traitement\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Répartion des variables <a class=\"anchor\" id=\"traitement\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Modèles\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Métriques\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# =====================\n",
    "\n",
    "# Définition de la cible (y) et des features (X)\n",
    "target = 'totalFare'\n",
    "\n",
    "features = [\n",
    "    \"legId\", \"searchDate\", \"flightDate\", \"startingAirport\", \"destinationAirport\",\n",
    "    \"fareBasisCode\", \"travelDuration\", \"elapsedDays\", \"isBasicEconomy\",\n",
    "    \"isRefundable\", \"isNonStop\", \"seatsRemaining\", \"totalTravelDistance\"\n",
    "]\n",
    "\n",
    "X = df_cleaned[features].copy()\n",
    "y = df_cleaned[target].copy()\n",
    "\n",
    "# Séparation en train et test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# =====================\n",
    "# Colonnes booléennes : on les convertit en int (0/1) si ce n'est pas déjà fait\n",
    "bool_cols = [\"isBasicEconomy\", \"isRefundable\", \"isNonStop\"]\n",
    "for col in bool_cols:\n",
    "    X_train[col] = X_train[col].astype(int, errors=\"ignore\")\n",
    "    X_test[col] = X_test[col].astype(int, errors=\"ignore\")\n",
    "\n",
    "numeric_features = [\"elapsedDays\", \"seatsRemaining\", \"totalTravelDistance\"] + bool_cols\n",
    "\n",
    "categorical_features = [\n",
    "    \"legId\",\n",
    "    \"searchDate\",\n",
    "    \"flightDate\",\n",
    "    \"startingAirport\",\n",
    "    \"destinationAirport\",\n",
    "    \"fareBasisCode\",\n",
    "    \"travelDuration\"\n",
    "]\n",
    "\n",
    "from sklearn.compose import make_column_selector\n",
    "\n",
    "numeric_transformer = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"missing\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", numeric_transformer, numeric_features),\n",
    "    (\"cat\", categorical_transformer, categorical_features)\n",
    "])\n",
    "\n",
    "models = {\n",
    "    \"DecisionTree\": DecisionTreeRegressor(random_state=42),\n",
    "    \"RandomForest\": RandomForestRegressor(random_state=42),\n",
    "    \"LinearRegression\": LinearRegression(),\n",
    "    \"XGBoost\": XGBRegressor(random_state=42, verbosity=0)  # verbosity=0 pour éviter les logs\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    # Pipeline = Preprocessing + Modèle\n",
    "    pipe = Pipeline([\n",
    "        (\"preprocessing\", preprocessor),\n",
    "        (\"regressor\", model)\n",
    "    ])\n",
    "    \n",
    "    # Entraînement\n",
    "    pipe.fit(X_train, y_train)\n",
    "    \n",
    "    # Prédiction\n",
    "    y_pred = pipe.predict(X_test)\n",
    "    \n",
    "    # Evaluation\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    results.append({\n",
    "        \"model\": model_name,\n",
    "        \"rmse\": rmse,\n",
    "        \"r2\": r2\n",
    "    })\n",
    "\n",
    "# Affichage des résultats\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 1) Conversion des dates en type datetime (si ce n’est pas déjà fait)\n",
    "# ----------------------------------------------------------\n",
    "df['searchDate'] = pd.to_datetime(df['searchDate'], errors='coerce')\n",
    "df['flightDate'] = pd.to_datetime(df['flightDate'], errors='coerce')\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 2) daysBetweenSearchAndFlight\n",
    "#    \\text{daysBetweenSearchAndFlight} = \\text{flightDate} - \\text{searchDate} (en jours)\n",
    "# ----------------------------------------------------------\n",
    "df['daysBetweenSearchAndFlight'] = (df['flightDate'] - df['searchDate']).dt.days\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 3) searchDayOfWeek et flightDayOfWeek\n",
    "#    Extraire le jour de la semaine (0 = Lundi, 6 = Dimanche)\n",
    "# ----------------------------------------------------------\n",
    "df['searchDayOfWeek'] = df['searchDate'].dt.dayofweek\n",
    "df['flightDayOfWeek'] = df['flightDate'].dt.dayofweek\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 4) searchMonth et flightMonth\n",
    "#    Extraire le mois (1 à 12)\n",
    "# ----------------------------------------------------------\n",
    "df['searchMonth'] = df['searchDate'].dt.month\n",
    "df['flightMonth'] = df['flightDate'].dt.month\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 5) flightWeekend (booléen)\n",
    "#    True si le jour du vol est un samedi ou dimanche (dayofweek in [5,6])\n",
    "# ----------------------------------------------------------\n",
    "df['flightWeekend'] = df['flightDayOfWeek'].isin([5, 6])\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 7) fareType (classification selon le référentiel Wikipédia)\n",
    "#    https://en.wikipedia.org/wiki/Fare_basis_code\n",
    "# ----------------------------------------------------------\n",
    "# On définit des sets de lettres pour chaque classe tarifaire\n",
    "FIRST = {'F', 'A', 'P'}\n",
    "BUSINESS = {'C', 'J', 'D', 'I', 'Z'}\n",
    "PREMIUM_ECONOMY = {'W', 'S', 'R'}\n",
    "ECONOMY = {'Y', 'B', 'M', 'U', 'H', 'Q', 'K', 'L', 'G', 'V', 'T', 'N', 'X', 'O', 'E'}\n",
    "\n",
    "def map_fare_type(code):\n",
    "    \"\"\"\n",
    "    Retourne la cabine probable (First, Business, Premium Economy, Economy, Unknown)\n",
    "    en se basant sur la première lettre du fareBasisCode.\n",
    "    \"\"\"\n",
    "    # Gérer le cas des NaN ou chaînes vides\n",
    "    if pd.isnull(code) or not code:\n",
    "        return 'Unknown'\n",
    "    \n",
    "    # On récupère la première lettre, en majuscule\n",
    "    first_char = str(code).strip().upper()[0]\n",
    "    \n",
    "    if first_char in FIRST:\n",
    "        return 'First'\n",
    "    elif first_char in BUSINESS:\n",
    "        return 'Business'\n",
    "    elif first_char in PREMIUM_ECONOMY:\n",
    "        return 'Premium Economy'\n",
    "    elif first_char in ECONOMY:\n",
    "        return 'Economy'\n",
    "    else:\n",
    "        return 'Unknown'\n",
    "\n",
    "df['fareType'] = df['fareBasisCode'].apply(map_fare_type)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 10) isOvernightFlight\n",
    "#     Si elapsedDays > 0, alors True, sinon False\n",
    "# ----------------------------------------------------------\n",
    "# elapsedDays est souvent 0 ou 1+ si on traverse la nuit\n",
    "df['isOvernightFlight'] = df['elapsedDays'] > 0\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 18) distanceBands\n",
    "#     \"short-haul\" (< 500 miles), \"medium-haul\" (500-1500 miles), \"long-haul\" (> 1500 miles)\n",
    "# ----------------------------------------------------------\n",
    "def define_distance_band(x):\n",
    "    if pd.isnull(x):\n",
    "        return 'unknown'   # ou None, selon préférence\n",
    "    elif x < 500:\n",
    "        return 'short-haul'\n",
    "    elif x <= 1500:\n",
    "        return 'medium-haul'\n",
    "    else:\n",
    "        return 'long-haul'\n",
    "\n",
    "df['distanceBands'] = df['totalTravelDistance'].apply(define_distance_band)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Vérification rapide\n",
    "# ----------------------------------------------------------\n",
    "print(df[[\n",
    "    'searchDate', 'flightDate', 'daysBetweenSearchAndFlight',\n",
    "    'searchDayOfWeek', 'flightDayOfWeek', 'searchMonth', 'flightMonth',\n",
    "    'flightWeekend', 'fareBasisCode', 'fareType',\n",
    "    'elapsedDays', 'isOvernightFlight',\n",
    "    'totalTravelDistance', 'distanceBands'\n",
    "]].head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
